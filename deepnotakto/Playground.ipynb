{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "from random import randint, sample, shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "size = plt.rcParams[\"figure.figsize\"]\n",
    "size[0] = 2\n",
    "size[1] = 2\n",
    "plt.rcParams[\"figure.figsize\"] = size\n",
    "\n",
    "import environment as env\n",
    "import visual\n",
    "import trainer as train\n",
    "import agents.random_plus as rp\n",
    "import agents.Q as Q\n",
    "import agents.human as human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = reload(env)\n",
    "_ = reload(train)\n",
    "_ = reload(Q)\n",
    "_ = reload(visual)\n",
    "_ = reload(rp)\n",
    "_ = reload(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainable Q-Learning agent for a 3x3 game\n",
    "QAgent = Q.Q([9, 100, 100, 100, 9], gamma = .6, epsilon = .1, beta = 5.0, name = \"PlaygroundTest\")\n",
    "# Trainer for the agent\n",
    "trainer = train.Trainer(QAgent)\n",
    "# Create a random playing agent\n",
    "RandomAgent = rp.RandomAgentPlus()\n",
    "# Create Human agents\n",
    "HumanP1 = human.Human()\n",
    "HumanP2 = human.Human()\n",
    "# Create an environment with a 3x3 board\n",
    "e = env.Env(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train against a random agent in GUI mode\n",
    "gui = visual.GameWithConfidences(e, QAgent, RandomAgent, max_games = -1, trainer_a1 = trainer.get_online(.00000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train against a random agent in normal mode\n",
    "e.play(QAgent, RandomAgent, 1000, trainer_a1 = trainer.get_online(.00000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ********** Done\n"
     ]
    }
   ],
   "source": [
    "# Train against previously set human moves\n",
    "s, a, r = [HumanP1.states, HumanP1.actions, HumanP1.rewards]\n",
    "trainer.offline(s, a, r, epochs = 10, learn_rate = .00000001, batch_size = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
